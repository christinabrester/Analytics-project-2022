{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results of MLPs on the validation data after running MLP_nowcasting.py (used for estimating power quality variables). \n",
    "Use the best models to estimate 'TDU', 'ITD', 'Q1act' (all three phases 'L1', 'L2', 'L3') and then, to generate deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sys\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def metric_IA(y_true,y_pred):\n",
    "    sse = K.sum(K.square(y_true - y_pred))\n",
    "    ia = K.sum(K.square(K.abs(y_true - K.mean(y_true)) + K.abs(y_pred - K.mean(y_true))))\n",
    "\n",
    "    ia = 1. - sse/ia\n",
    "    return ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality metrics\n",
    "def IA(true, predicted):  \n",
    "    true = true.ravel()\n",
    "    predicted = predicted.ravel()\n",
    "    return 1 - np.sum((true-predicted)**2)/np.sum((np.abs(predicted-np.mean(true))+np.abs(true-np.mean(true)))**2)\n",
    "\n",
    "def RMSE(true, predicted):\n",
    "    true = true.ravel()\n",
    "    predicted = predicted.ravel()\n",
    "    return np.sqrt(np.mean((true-predicted)**2))\n",
    "\n",
    "def MAE(true, predicted):\n",
    "    true = true.ravel()\n",
    "    predicted = predicted.ravel()\n",
    "    return np.mean(np.abs(true-predicted))\n",
    "\n",
    "def BIAS(true, predicted):\n",
    "    true = true.ravel()\n",
    "    predicted = predicted.ravel()\n",
    "    return np.mean(predicted-true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our study, there are two experiments: for the ventilation system and for the main distribution board\n",
    "# Here we initialize a variable \"exp_name\", which is used to define a path to the measurement data\n",
    "\n",
    "exp_name = 'main_distribution_board_2018_2020' # or exp_name = 'ventilation_system_2018_2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = ['L1', 'L2', 'L3']\n",
    "pq_variables = ['TDU', 'ITD', 'Q1act'] # Variables estimated in nowcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the best MLP architectures and the number of epochs\n",
    "best_mlp_settings = dict()\n",
    "\n",
    "exp_runs = 10\n",
    "\n",
    "for pq_variable in pq_variables:\n",
    "    best_mlp_settings[pq_variable] = dict()\n",
    "    \n",
    "    for phase in phases:\n",
    "        best_mlp_settings[pq_variable][phase] = dict()\n",
    "        \n",
    "        results = pd.DataFrame()\n",
    "\n",
    "        for i in range(exp_runs):\n",
    "            result = pd.read_csv(\"{}/results_mlp_{}_{}_run_{}.csv\".format(exp_name, pq_variable, phase, i), index_col = 0)\n",
    "            results = results.append(result, ignore_index = True)\n",
    "          \n",
    "        summary_avr = results.groupby(['nneurons']).mean()\n",
    "        for metric in ['rmse', 'mae', 'ia']:\n",
    "            best_nn = summary_avr.index[np.argmin(summary_avr['{}_valid'.format(metric)])]\n",
    "            epochs = summary_avr.epochs[np.argmin(summary_avr['{}_valid'.format(metric)])]\n",
    "            \n",
    "            best_mlp_settings[pq_variable][phase][metric] = (ast.literal_eval(best_nn), epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mehods to run MLP with the best settings found\n",
    "\n",
    "class NeuralNet(ABC):\n",
    "    MAX_EPOCHS = 1000\n",
    "    BATCH_SIZE = 128\n",
    "    LOSS = 'mean_absolute_error'  \n",
    "    METRICS = [metric_IA, 'mean_squared_error']\n",
    "    LEARNING_RATE = 1e-3\n",
    "    ACTIVATION = 'tanh'\n",
    "    NNEURONS = [8]\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.batch_size = kwargs.get('batch_size', NeuralNet.BATCH_SIZE)\n",
    "        self.loss = kwargs.get('loss', NeuralNet.LOSS)\n",
    "        self.metrics = kwargs.get('metrics', NeuralNet.METRICS)\n",
    "        self.max_epochs = kwargs.get('metrics', NeuralNet.MAX_EPOCHS)\n",
    "        self.learning_rate = kwargs.get('learning_rate', NeuralNet.LEARNING_RATE)\n",
    "        self.activation = kwargs.get('activation', NeuralNet.ACTIVATION)\n",
    "        self.nneurons = kwargs.get('nneurons', NeuralNet.NNEURONS[:])\n",
    "\n",
    "        self.model = Sequential()\n",
    "        #self.random_weights = None # used to re-initialize the model in new runs\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def build_model(self):\n",
    "        pass\n",
    "\n",
    "    def train_model_with_valid(self, data_train_x, data_train_y, data_val_x, data_val_y):\n",
    "        '''\n",
    "        A training mode to define an optimal number of epochs using validation data.\n",
    "        Returns a tuple (opt_epochs, opt_val_loss)\n",
    "        '''\n",
    "\n",
    "        #self.model.set_weights(self.random_weights) # re-initialize the model\n",
    "        \n",
    "        opt = Adam(learning_rate=self.learning_rate)\n",
    "        \n",
    "        self.model.compile(\n",
    "            loss = self.loss,\n",
    "            optimizer = opt,\n",
    "            metrics =  self.metrics\n",
    "        )\n",
    "        \n",
    "        earlystopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=100, verbose=0, mode='min', restore_best_weights=True)\n",
    "        \n",
    "        self.model.fit(\n",
    "            data_train_x, data_train_y,\n",
    "            verbose=0,\n",
    "            shuffle=True,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.max_epochs,\n",
    "            validation_data=(data_val_x, data_val_y),\n",
    "            callbacks=[earlystopping]\n",
    "        )\n",
    "        \n",
    "        hist = self.model.history.history['val_loss']\n",
    "        n_epochs_best = np.argmin(hist)\n",
    "        scores_validation = self.model.evaluate(data_val_x, data_val_y, verbose=0, batch_size=data_val_x.shape[0])\n",
    "\n",
    "        return n_epochs_best\n",
    "    \n",
    "    def train_model(self, data_x, data_y, opt_epochs):\n",
    "        '''\n",
    "        A training mode without validation when the optimal number of epochs is known.\n",
    "        '''\n",
    "        #self.model.set_weights(self.random_weights) # re-initialize the model\n",
    "        \n",
    "        opt = Adam(learning_rate=self.learning_rate)\n",
    "        self.model.compile(\n",
    "            loss = self.loss,\n",
    "            optimizer = opt,\n",
    "            metrics =  self.metrics\n",
    "        )\n",
    "        self.model.fit(\n",
    "            data_x, data_y,\n",
    "            verbose=0,\n",
    "            shuffle=True,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=int(opt_epochs),\n",
    "            validation_split = 0.0\n",
    "        )\n",
    "\n",
    "    def predict(self, data_x):\n",
    "        return self.model.predict(data_x, batch_size = data_x.shape[0])\n",
    "            \n",
    "\n",
    "class MLP(NeuralNet):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build_model(self, input_cols):\n",
    "        self.model = Sequential()\n",
    "        for i, nn in enumerate(self.nneurons):\n",
    "            if i == 0:\n",
    "                self.model.add(Dense(nn, input_shape=(input_cols,), activation = self.activation))\n",
    "            else:\n",
    "                self.model.add(Dense(nn, activation = self.activation))\n",
    "        self.model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "        #self.random_weights = self.model.get_weights() # save random weights to re-initialize the model in new runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to train MLP with the predefided settings on the given training and test data \n",
    "\n",
    "def modeling(training_data, test_data, inputs, output, NN, opt_epochs):\n",
    "    \n",
    "    training_data_inputs = training_data.loc[:, inputs].copy()\n",
    "    test_data_inputs = test_data.loc[:, inputs].copy()\n",
    "\n",
    "    training_data_output = pd.DataFrame(training_data.loc[:, output].copy(), columns = [output])\n",
    "    test_data_output = pd.DataFrame(test_data.loc[:, output].copy(), columns = [output])\n",
    "    \n",
    "    # 1. Train scalers\n",
    "    scaler_inputs = MinMaxScaler()\n",
    "    scaler_inputs.fit(training_data_inputs)\n",
    "    \n",
    "    training_data_inputs_scaled = scaler_inputs.transform(training_data_inputs)\n",
    "    test_data_inputs_scaled = scaler_inputs.transform(test_data_inputs)\n",
    "    #---------------------------------------------------------------------\n",
    "    scaler_output = MinMaxScaler()\n",
    "    scaler_output.fit(training_data_output)\n",
    "    \n",
    "    training_data_output_scaled = scaler_output.transform(training_data_output)\n",
    "    test_data_output_scaled = scaler_output.transform(test_data_output)\n",
    "    #---------------------------------------------------------------------\n",
    "    \n",
    "    # 2. Training and test performance\n",
    "    \n",
    "    NN.build_model(training_data_inputs_scaled.shape[1])\n",
    "    NN.train_model(training_data_inputs_scaled, training_data_output_scaled.ravel(), opt_epochs)\n",
    "    \n",
    "    pred_train = NN.predict(training_data_inputs_scaled).reshape(-1, 1)\n",
    "    \n",
    "    pred_train = scaler_output.inverse_transform(pred_train)\n",
    "    training_data_output_scaled = scaler_output.inverse_transform(training_data_output_scaled)\n",
    "    \n",
    "    ia_train = IA(training_data_output_scaled, pred_train)\n",
    "    rmse_train = RMSE(training_data_output_scaled, pred_train)\n",
    "    mae_train = MAE(training_data_output_scaled, pred_train)\n",
    "    bias_train = BIAS(training_data_output_scaled, pred_train)\n",
    "    \n",
    "    pred_test = NN.predict(test_data_inputs_scaled).reshape(-1, 1)\n",
    "    pred_test = scaler_output.inverse_transform(pred_test)\n",
    "\n",
    "    test_data_output = scaler_output.inverse_transform(test_data_output_scaled)\n",
    "    \n",
    "    ia_test = IA(test_data_output, pred_test)\n",
    "    rmse_test = RMSE(test_data_output, pred_test)\n",
    "    mae_test = MAE(test_data_output, pred_test)\n",
    "    bias_test = BIAS(test_data_output, pred_test)\n",
    "    \n",
    "    \n",
    "    result = {\"ia_train\": ia_train, \"rmse_train\": rmse_train, \"mae_train\": mae_train, \"bias_train\": bias_train, \n",
    "              \"ia_test\": ia_test, \"rmse_test\": rmse_test, \"mae_test\": mae_test, \"bias_test\": bias_test}\n",
    "    \n",
    "    pred_train = pd.DataFrame(pred_train, index = training_data.index, columns = [\"predictions\"])\n",
    "    pred_test = pd.DataFrame(pred_test, index = test_data.index, columns = [\"predictions\"])\n",
    "\n",
    "    return pred_train, pred_test, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create html to visualize the results of nowcasting\n",
    "\n",
    "def visualize(pq_variable, phase, nneurons, results, test_year):\n",
    "    \n",
    "    fig = make_subplots(rows=2, cols=4, \n",
    "                        specs=[[{'colspan': 3}, {}, {}, {}],[{'colspan': 3}, {}, {}, {}]],\n",
    "                        subplot_titles = [\n",
    "        'Output {}, phase {}: Training data. RMSE = {}, MAE = {}, IA = {}, BIAS = {}'.format(pq_variable, phase,\n",
    "                                                                                  round(results['rmse_train'], 2), \n",
    "                                                                                  round(results['mae_train'], 2), \n",
    "                                                                                  round(results['ia_train'], 2),\n",
    "                                                                                  round(results['bias_train'], 2)),\n",
    "                                                                                  None, None,\n",
    "                                                                                  'Training data',\n",
    "        'Output {}, phase {}: Test data. RMSE = {}, MAE = {}, IA = {}, BIAS = {}'.format(pq_variable, phase,\n",
    "                                                                              round(results['rmse_test'], 2), \n",
    "                                                                              round(results['mae_test'], 2), \n",
    "                                                                              round(results['ia_test'], 2),\n",
    "                                                                              round(results['bias_test'], 2)),\n",
    "                                                                              None, None,\n",
    "                                                                              'Test data'])\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=pd.to_datetime(training_data.Timestamp), \n",
    "                             y=training_data.loc[:, output], mode='markers', marker=dict(size=5),\n",
    "                             name='measured', legendgroup = '1'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=pd.to_datetime(predictions_train.Timestamp), marker=dict(size=5),\n",
    "                             y=predictions_train.loc[:, 'predictions'], mode='markers',\n",
    "                             name='predicted', legendgroup = '1'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=training_data.loc[:, output], \n",
    "                             y=predictions_train.loc[:, 'predictions'], mode='markers', marker=dict(size=3),\n",
    "                             showlegend = False, legendgroup = '1'), row=1, col=4)\n",
    "    fig.add_trace(go.Scatter(x=[min(training_data.loc[:, output].min(), predictions_train.loc[:, 'predictions'].min()), \n",
    "                                max(training_data.loc[:, output].max(), predictions_train.loc[:, 'predictions'].max())],\n",
    "                             y=[min(training_data.loc[:, output].min(), predictions_train.loc[:, 'predictions'].min()), \n",
    "                                max(training_data.loc[:, output].max(), predictions_train.loc[:, 'predictions'].max())],\n",
    "                            mode=\"lines\",\n",
    "                            line=go.scatter.Line(color=\"blue\", dash = \"dot\", width = 2),\n",
    "                            name=\"Ref. line: y = x\", legendgroup = '1'), row=1, col=4)\n",
    "\n",
    "    x = training_data.loc[:, [output]].dropna()\n",
    "    y = predictions_train.loc[:, 'predictions'].dropna()\n",
    "    common_index = list(set(x.index).intersection(set(y.index)))\n",
    "    \n",
    "    reg = LinearRegression().fit(x.loc[common_index], y.loc[common_index])    \n",
    "    fig.add_trace(go.Scatter(x=[training_data.loc[:, output].min(), training_data.loc[:, output].max()],\n",
    "                             y=[training_data.loc[:, output].min()*reg.coef_[0] + reg.intercept_, \n",
    "                                training_data.loc[:, output].max()*reg.coef_[0] + reg.intercept_],\n",
    "                            mode=\"lines\",\n",
    "                            line=go.scatter.Line(color=\"red\", dash = \"dot\", width = 2),\n",
    "                            name=\"OLS line: y = {} * x + {}\".format(round(reg.coef_[0], 3), round(reg.intercept_,3)),\n",
    "                            legendgroup = '1', legendgrouptitle_text='Training data'), \n",
    "                            row=1, col=4)\n",
    "\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=pd.to_datetime(test_data.Timestamp), \n",
    "                             y=test_data.loc[:, output], mode='markers', marker=dict(size=5),\n",
    "                             name='measured', legendgroup = '2'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=pd.to_datetime(predictions_test.Timestamp), \n",
    "                             y=predictions_test.loc[:, 'predictions'], mode='markers', marker=dict(size=5),\n",
    "                             name='predicted', legendgroup = '2'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=test_data.loc[:, output], \n",
    "                             y=predictions_test.loc[:, 'predictions'], mode='markers', marker=dict(size=2),\n",
    "                             showlegend = False, legendgroup = '2'), row=2, col=4)\n",
    "    fig.add_trace(go.Scatter(x=[min(test_data.loc[:, output].min(), predictions_test.loc[:, 'predictions'].min()), \n",
    "                                max(test_data.loc[:, output].max(), predictions_test.loc[:, 'predictions'].max())],\n",
    "                             y=[min(test_data.loc[:, output].min(), predictions_test.loc[:, 'predictions'].min()), \n",
    "                                max(test_data.loc[:, output].max(), predictions_test.loc[:, 'predictions'].max())],\n",
    "                            mode=\"lines\",\n",
    "                            line=go.scatter.Line(color=\"blue\", width = 2),\n",
    "                            name = \"Ref. line: y = x\", legendgroup = '2'), row=2, col=4)\n",
    "    \n",
    "    x = test_data.loc[:, [output]].dropna()\n",
    "    y = predictions_test.loc[:, 'predictions'].dropna()\n",
    "    common_index = list(set(x.index).intersection(set(y.index)))\n",
    "    \n",
    "    reg = LinearRegression().fit(x.loc[common_index], y.loc[common_index])    \n",
    "    fig.add_trace(go.Scatter(x=[test_data.loc[:, output].min(), test_data.loc[:, output].max()],\n",
    "                             y=[test_data.loc[:, output].min()*reg.coef_[0] + reg.intercept_, \n",
    "                                test_data.loc[:, output].max()*reg.coef_[0] + reg.intercept_],\n",
    "                            mode=\"lines\",\n",
    "                            line=go.scatter.Line(color=\"red\", width = 2),\n",
    "                            name=\"OLS line: y = {} * x + {}\".format(round(reg.coef_[0], 3), round(reg.intercept_,3)),\n",
    "                            legendgroup = '2', legendgrouptitle_text='Test data'), \n",
    "                            row=2, col=4)\n",
    "\n",
    "    fig.update_layout(showlegend=True, title = '{}, neurons = {}'.format(folder, nneurons), legend_tracegroupgap = 10)\n",
    "    \n",
    "    fig.update_layout(\n",
    "    xaxis8_title=\"Measured\",\n",
    "    yaxis8_title=\"Predicted\",\n",
    "    yaxis8={'side': 'right'}  )\n",
    "\n",
    "    #fig.show()\n",
    "\n",
    "    plotly.offline.plot(fig, filename='{}/TEST {} {} {}.html'.format(exp_name, test_year, pq_variable, phase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save measurements, estimations, and deviations for a particular PQ variable in one file \n",
    "\n",
    "def save_predictions(exp_name, pq_variable, phase, test_year):\n",
    "    \n",
    "    df = pd.DataFrame(pd.to_datetime(test_data.Timestamp))\n",
    "    df['measured'] = test_data.loc[:, output]\n",
    "    df['model outcome'] = predictions_test.loc[:, 'predictions']\n",
    "    df['deviation (measured - model)'] = df['measured'] - df['model outcome']\n",
    "    \n",
    "    df.to_csv('{}/PQ {} {} {}.csv'.format(exp_name, pq_variable, phase, test_year))\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDU   L1\n",
      "[128, 64, 32]\n",
      "TDU   L2\n",
      "[128, 128, 128]\n",
      "TDU   L3\n",
      "[128, 128, 128]\n",
      "ITD   L1\n",
      "[64, 32, 16]\n",
      "ITD   L2\n",
      "[128, 128, 128]\n",
      "ITD   L3\n",
      "[128, 128, 128]\n",
      "Q1act   L1\n",
      "[64, 32, 16]\n",
      "Q1act   L2\n",
      "[16, 16, 16]\n",
      "Q1act   L3\n",
      "[128, 128, 128]\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------\n",
    "# Run feature engineering for different years\n",
    "#---------------------------------------------\n",
    "\n",
    "training_data = pd.read_csv('{}/2018_2019_winter_10min.csv'.format(exp_name))\n",
    "\n",
    "# Use one of the test years 2019_2020, 2020_2021, or 2021_2022 to generate new features\n",
    "test_year = '2019_2020'\n",
    "test_data = pd.read_csv('{}/{}_winter_10min.csv'.format(exp_name, test_year))\n",
    "\n",
    "training_data_noNaN = training_data.dropna().copy()\n",
    "test_data_noNaN = test_data.dropna().copy()\n",
    "\n",
    "column_names = training_data.columns\n",
    "\n",
    "column_names_L1 = [var for var in column_names if 'L1' in var ]\n",
    "column_names_L2 = [var for var in column_names if 'L2' in var ]\n",
    "column_names_L3 = [var for var in column_names if 'L3' in var ]\n",
    "\n",
    "column_names_dict = {'L1': column_names_L1,\n",
    "                     'L2': column_names_L2,\n",
    "                     'L3': column_names_L3}\n",
    "\n",
    "training_timestamps = training_data_noNaN.loc[:, 'Timestamp']\n",
    "\n",
    "for pq_variable in pq_variables:\n",
    "    for phase in phases:\n",
    "        \n",
    "        for exp_run in range(1):\n",
    "            \n",
    "            output = pq_variable + phase\n",
    "            inputs = column_names_dict[phase].copy()\n",
    "            inputs.remove(output)\n",
    "            inputs.remove('Q1{}'.format(phase))\n",
    "            inputs.remove('I1{}'.format(phase))\n",
    "            inputs.append('U0U1')\n",
    "            inputs.append('U2U1')\n",
    "            inputs.append('Freq')\n",
    "\n",
    "            predictions_train = pd.DataFrame(training_data.loc[:, \"Timestamp\"].copy(), index = training_data.index)\n",
    "            predictions_test = pd.DataFrame(test_data.loc[:, \"Timestamp\"].copy(), index = test_data.index)\n",
    "\n",
    "            print(pq_variable, ' ', phase)\n",
    "\n",
    "            nneurons = best_mlp_settings[pq_variable][phase]['mae'][0]\n",
    "            epochs = best_mlp_settings[pq_variable][phase]['mae'][1]\n",
    "\n",
    "            print(nneurons)\n",
    "\n",
    "            model = MLP(nneurons = nneurons) \n",
    "            pred_train, pred_test, result = modeling(training_data_noNaN, test_data_noNaN, inputs, output, model, epochs)\n",
    "\n",
    "            predictions_train = predictions_train.join(pred_train)\n",
    "            predictions_test = predictions_test.join(pred_test)\n",
    "\n",
    "            saved_df = save_predictions(exp_name, pq_variable, phase, test_year)\n",
    "            \n",
    "            # Uncomment, if visualization is needed\n",
    "            # visualize(pq_variable, phase, nneurons, result, test_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
